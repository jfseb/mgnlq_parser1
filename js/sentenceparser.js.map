{"version":3,"sources":["/projects/nodejs/botbuilder/mgnlq_parser1/src//projects/nodejs/botbuilder/mgnlq_parser1/src/../src/sentenceparser.ts"],"names":[],"mappings":"AAAA,YAAY,CAAA;;;AAEZ,+FAA+F;AAC/F,0EAA0E;AAE1E,+CAAgG;AAEhG,gCAAgC;AAEhC,yCAAyC;AAGzC,MAAM,QAAQ,GAAG,KAAK,CAAC,gBAAgB,CAAC,CAAC;AAEzC,6CAA6C;AAC7C,yCAAyC;AACzC,6BAA6B;AAI3B,IAAI,WAAW,GAAG,UAAU,CAAC,WAAW,CAAC;AACzC,IAAI,KAAK,GAAG,UAAU,CAAC,KAAK,CAAC;AAC7B,IAAI,MAAM,GAAG,UAAU,CAAC,MAAM,CAAC;AAGjC,6CAAgD;AAE9C,IAAI,UAAU,GAAG,WAAW,CAAC,EAAC,IAAI,EAAE,YAAY,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;AAEnE,UAAU,CAAC,KAAK,GAAG,KAAK,CAAC,OAAO,CAAC;AAEjC,qCAA0E;AAC1E,iFAAiF;AACjF,IAAI,SAAS,GAAG,MAAM,CAAC,IAAI,CAAC,eAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,eAAC,CAAC,GAAG,CAAC,CAAC,CAAC;AAGpD,SAAgB,SAAS,CAAC,CAAkB,EAAE,KAAc,EAAE,EAAQ;IACpE,IAAI,CAAC,CAAC,CAAC,IAAI,EAAE;QACX,MAAM,IAAI,KAAK,CAAC,qBAAqB,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;KAC5D;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,qBAAO,CAAC,QAAQ,CAAC,QAAQ,EAAE;QACjD,OAAO,EAAE,KAAK,EAAG,KAAK,EAAG,WAAW,EAAG,KAAK,EAAE,MAAM,EAAG,CAAC,EAAE,SAAS,EAAG,uBAAc,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC;KACtG;IAAA,CAAC;IACF,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,OAAO,EAAE,KAAK,EAAG,MAAM,EAAG,WAAW,EAAG,KAAK,EAAE,MAAM,EAAG,CAAC,EAAE,SAAS,EAAG,eAAC,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;KAC3F;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,mGAAmG;QACnG,sCAAsC;QACtC,OAAO,EAAE,KAAK,EAAG,QAAQ,EAAG,WAAW,EAAG,KAAK,EAAE,MAAM,EAAG,CAAC,EAAE,SAAS,EAAG,eAAC,CAAC,OAAO,CAAC,SAAS,EAAE,CAAC;KAChG;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,OAAO,EAAE,KAAK,EAAG,KAAK,EAAG,WAAW,EAAG,KAAK,EAAE,MAAM,EAAG,CAAC,EAAE,SAAS,EAAG,eAAC,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC;KACzF;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,OAAO,EAAE,KAAK,EAAG,KAAK,EAAG,WAAW,EAAG,KAAK,EAAE,MAAM,EAAG,CAAC,EAAE,SAAS,EAAG,eAAC,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC;KAC3F;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,IAAI,GAAG,GAAG,CAAC,CAAC,aAAa,CAAC,WAAW,EAAE,CAAC;QACxC,IAAI,QAAQ,GAAG,GAAG,CAAC,OAAO,CAAC,IAAI,EAAC,GAAG,CAAC,CAAC;QACrC,gCAAgC;QAChC,4CAA4C;QAC5C,+CAA+C;QAC/C,sDAAsD;QACtD,IAAI,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE;YACjB,yCAAyC;YACzC,MAAM,IAAI,KAAK,CAAC,gCAAgC,GAAG,CAAC,CAAC,aAAa,GAAE,GAAG,CAAC,CAAC;SAC1E;QACD,+CAA+C;QAC/C,OAAO,EAAE,KAAK,EAAG,CAAC,CAAC,aAAa,EAAE,MAAM,EAAG,CAAC,EAAE,WAAW,EAAG,KAAK,EAAE,SAAS,EAAG,eAAC,CAAC,QAAQ,CAAC,CAAC,SAAS,EAAE,CAAC;KACxG;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,IAAI,GAAG,GAAG,CAAC,CAAC,aAAa,CAAC,WAAW,EAAE,CAAC;QACxC,gDAAgD;QAChD,IAAI,OAAO,GAAG,uBAAc,CAAC,GAAG,CAAC,CAAC;QAClC,wEAAwE;QACxE,IAAI,CAAC,OAAO,EAAE;YACZ,QAAQ,CAAC,MAAM,CAAC,IAAI,CAAC,uBAAc,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC;YACpD,MAAM,IAAI,KAAK,CAAC,gCAAgC,GAAG,CAAC,CAAC,aAAa,GAAG,aAAa,GAAG,CAAC,QAAQ,CAAC,GAAG,iBAAiB,GAAG,MAAM,CAAC,mBAAmB,CAAC,uBAAc,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAE,YAAY,CAAC,CAAC;YAC3L,mBAAmB;SACpB;QACD,qFAAqF;QACrF,OAAO,EAAE,KAAK,EAAG,CAAC,CAAC,aAAa,EAAE,MAAM,EAAG,CAAC,EAAE,WAAW,EAAG,KAAK,EAAE,SAAS,EAAG,OAAO,CAAC,SAAS,EAAE,CAAC;KACpG;IACD,IAAI,CAAC,CAAC,IAAI,CAAC,QAAQ,KAAK,GAAG,EAAE;QAC3B,IAAI,GAAG,GAAG,CAAC,CAAC,aAAa,CAAC,WAAW,EAAE,CAAC;QACxC,IAAI,OAAO,GAAG,eAAC,CAAC,GAAG,CAAC,CAAC;QACrB,IAAI,CAAC,OAAO,EAAE;YACZ,QAAQ,CAAC,+BAA+B,GAAG,CAAC,CAAC,aAAa,CAAC,CAAC;YAC5D,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;SAClB;QACD,OAAO,EAAE,KAAK,EAAG,CAAC,CAAC,aAAa,EAAE,MAAM,EAAG,CAAC,EAAE,WAAW,EAAG,KAAK,EAAE,SAAS,EAAG,OAAO,CAAC,SAAS,EAAE,CAAC;KACpG;IACD,MAAM,IAAI,KAAK,CAAC,gBAAgB,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;AACxD,CAAC;AA1DD,8BA0DC;AAED,MAAM,MAAM;IAAZ;QACG,aAAQ,GAAG,UAAS,QAA6B;YAChD,QAAQ,CAAE,GAAE,EAAE,CAAC,2BAA2B,GAAG,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAC,CAAC;YACvE,OAAO,QAAQ,CAAC,GAAG,CAAE,CAAC,CAAC,EAAC,KAAK,EAAE,EAAE;gBAC5B,IAAI,CAAC,GAAI,SAAS,CAAC,CAAC,EAAE,KAAK,EAAE,uBAAc,CAAC,CAAC;gBAC9C,QAAQ,CAAC,gBAAgB,GAAG,KAAK,GAAG,KAAK,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC/D,OAAO,CAAC,CAAC;YACb,CAAC,CAAC,CAAC;QACL,CAAC,CAAA;IACH,CAAC;CAAA;AAAA,CAAC;AAEF,SAAgB,QAAQ;IACtB,OAAO,IAAI,MAAM,EAAE,CAAC;AACtB,CAAC;AAFD,4BAEC;AAEC;;;;;;;;;;;EAWA;AACE,IAAI,WAAW,GAAG,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC;AA4DxC,kCAAW;AAzDd,SAAS,KAAK,CAAC,MAAc,EAAE,SAAkB;IAC/C,MAAM,MAAM,GAAG,IAAI,YAAY,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;IACrD,+CAA+C;IAC/C,IAAI,GAAG,GAAG,MAAM,CAAC,SAAS,CAAC,EAAE,CAAC;IAC7B,IAAI,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE;QAC7B,QAAQ,CAAC,GAAG,EAAE,CAAC,0BAA0B,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,EAAC,SAAS,EAAC,CAAC,CAAC,CAAC,CAAC;QACvF,IAAI,CAAC,GAAG,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,CAAS,CAAC,SAAS,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,CAAC;KACT;IACD,OAAO,GAAG,CAAC;AACb,CAAC;AA+CE,sBAAK;AA1CP,CAAC;AAIF,SAAgB,mBAAmB,CAAC,CAAU,EAAE,KAAuB,EAAE,KAAW;IAClF,IAAI,GAAG,GAAG,iBAAM,CAAC,aAAa,CAAC,CAAC,EAAE,KAAK,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE,CAAC,mBAAmB,CAAE,CAAC;IAC/E,QAAQ,CAAC,GAAG,EAAE,CAAA,QAAQ,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,EAAE,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5D,IAAI,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC,EAAE,EAAE,GAAU,CAAqB,CAAC;IAC7D,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,EAAE,CAAC;IAChC,IAAI,CAAC,IAAI,GAAG,GAAG,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,QAAQ,EAAE,KAAK,EAAE,EAAE;QAChD,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC;QAC3B,IAAI,YAAY,GAAG,QAAQ,EAAE,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC;QACjD,QAAQ,CAAE,GAAG,EAAE;YACb,IAAI,QAAQ,GAAG,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,EAAE,CAAE,IAAI,MAAM,KAAK,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,MAAM,IAAI,CAAC,CAAC,MAAM,CAAC,aAAa,IAAI,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,GAAG,CAAE,CAAC;YACpK,OAAO,WAAW,GAAG,KAAK,GAAG,OAAO,GAAG,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC7D,CAAC,CAAC,CAAC;QACH,wGAAwG;QACxG,IAAI;YACF,IAAI,GAAG,GAAG,KAAK,CAAC,YAAY,EAAE,eAAe,CAAC,CAAC;YAC/C,QAAQ,CAAC,GAAG,EAAE;gBACZ,OAAO,QAAQ,GAAG,KAAK,GAAG,OAAO,GAAG,GAAG,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC;YACzD,CAAC,CAAC,CAAC;YACH,OAAO,GAAG,CAAC;SACZ;QAAC,OAAO,CAAC,EAAE;YACV,QAAQ,CAAC,GAAE,EAAE,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,SAAS,EAAC,SAAS,EAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,SAAS,CAAA,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAA,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;YACvH,QAAQ,CAAC,GAAE,EAAE,CAAC,cAAc,GAAG,mBAAQ,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC,CAAC;YAC5D,IAAI,EAAE,GAAG,WAAW,CAAC,WAAW,CAAC,CAAC,CAAC,SAAS,EAAC,QAAQ,CAAC,CAAC;YACvD,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,EAAE,CAAC;YAChC,QAAQ,CAAC,cAAc,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC;YAExC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG;gBACnB,QAAQ,EAAG,uBAAe;gBAC1B,IAAI,EAAG,CAAC,CAAC,QAAQ,EAAE,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC;aACtB,CAAC;SACzB;QACD,OAAO,SAAS,CAAC;IACnB,CAAC,CAAC,CAAC;IACH,OAAO,IAAI,CAAC;AACd,CAAC;AAlCD,kDAkCC","file":"sentenceparser.js","sourcesContent":["'use strict'\r\n\r\n// based on: http://en.wikibooks.org/wiki/Algorithm_implementation/Strings/Levenshtein_distance\r\n// and:  http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\r\n\r\nimport { ErBase as ErBase, Sentence as Sentence, IFErBase as IFErBase } from './match/er_index';\r\n\r\nimport * as debug from 'debugf';\r\n\r\nimport * as SelectParser from './parser';\r\n\r\n\r\nconst debuglog = debug('sentenceparser');\r\n\r\nimport * as FormatError from './formaterror';\r\nimport * as chevrotain from 'chevrotain';\r\nimport * as AST from './ast';\r\n\r\nimport { ASTNodeType as NT} from './ast';\r\n\r\n  var createToken = chevrotain.createToken;\r\n  var Lexer = chevrotain.Lexer;\r\n  var Parser = chevrotain.Parser;\r\n\r\n\r\nimport { IFModel as IFModel} from 'mgnlq_model';\r\n\r\n  var WhiteSpace = createToken({name: \"WhiteSpace\", pattern: /\\s+/});\r\n\r\n  WhiteSpace.GROUP = Lexer.SKIPPED;\r\n\r\n  import { OperatorLookup as OperatorLookup, Tokens as T }  from './tokens';\r\n  // whitespace is normally very common so it is placed first to speed up the lexer\r\n  var allTokens = Object.keys(T).map(key => T[key]);\r\n\r\n\r\nexport function makeToken(t : IFErBase.IWord, index : number, OL : any ) {\r\n  if (!t.rule) {\r\n    throw new Error(\"Token without rule \" + JSON.stringify(t));\r\n  }\r\n  if (t.rule.wordType === IFModel.WORDTYPE.CATEGORY) {\r\n    return { image : \"CAT\",  startOffset : index, bearer : t, tokenType : OperatorLookup.CAT.tokenType };\r\n  };\r\n  if (t.rule.wordType === 'F') {\r\n    return { image : \"FACT\",  startOffset : index, bearer : t, tokenType : T.FACT.tokenType };\r\n  }\r\n  if (t.rule.wordType === 'N') {\r\n    //console.log( 'tokentype is ' +  T[\"Integer\"].tokenType  +  ' ' + JSON.stringify( T[\"Integer\"] ));\r\n    // TODO i parses as integer -> integer\r\n    return { image : \"NUMBER\",  startOffset : index, bearer : t, tokenType : T.Integer.tokenType };\r\n  }\r\n  if (t.rule.wordType === 'D') {\r\n    return { image : \"DOM\",  startOffset : index, bearer : t, tokenType : T.DOM.tokenType };\r\n  }\r\n  if (t.rule.wordType === 'A') {\r\n    return { image : \"ANY\",  startOffset : index, bearer : t, tokenType : T.AnANY.tokenType };\r\n  }\r\n  if (t.rule.wordType === 'M') {\r\n    var tlc = t.matchedString.toLowerCase();\r\n    var tlcClean = tlc.replace(/ /g,'_');\r\n    //debulog(\">\" + tlcClean + \"<\");\r\n    //debulog(Object.keys(T).indexOf(\"domain\"));\r\n    //debulog(\">>>\" + JSON.stringify(T[\"domain\"]));\r\n    //debulog(\"> token >>\" + JSON.stringify(T[tlcClean]));\r\n    if (!OL[tlcClean]) {\r\n      //debuglog(Object.keys(T).join('\\\" \\\"'));\r\n      throw new Error(\"unknown token of type M with >\" + t.matchedString+ \"<\");\r\n    }\r\n    //debuglog(\" here we go\" + typeof T[\"domain\"]);\r\n    return { image : t.matchedString, bearer : t, startOffset : index, tokenType : T[\"domain\"].tokenType };\r\n  }\r\n  if (t.rule.wordType === 'O') {\r\n    var tlc = t.matchedString.toLowerCase();\r\n    //var tlcClean = tlc; //  tlc.replace(/ /g,'_');\r\n    var opToken = OperatorLookup[tlc];\r\n    //console.log(' here mapped with _ ' + tlcClean + ' ' + Object.keys(T));\r\n    if (!opToken) {\r\n      debuglog(Object.keys(OperatorLookup).join('\\\" \\\"'));\r\n      throw new Error(\"unknown token of type O with >\" + t.matchedString + \"< cleansed>\" + (tlcClean) + \"< not found in \" + Object.getOwnPropertyNames(OperatorLookup).join('\\n') +\" , add to \");\r\n      //process.exit(-1);\r\n    }\r\n    //console.log( ' here image  for O' + t.matchedString + ' ' + T[tlcClean].tokenType);\r\n    return { image : t.matchedString, bearer : t, startOffset : index, tokenType : opToken.tokenType };\r\n  }\r\n  if (t.rule.wordType === 'I') {\r\n    var tlc = t.matchedString.toLowerCase();\r\n    var opToken = T[tlc];\r\n    if (!opToken) {\r\n      debuglog(\"unknown token of type I with \" + t.matchedString);\r\n      process.exit(-1);\r\n    }\r\n    return { image : t.matchedString, bearer : t, startOffset : index, tokenType : opToken.tokenType };\r\n  }\r\n  throw new Error(\"unknown token \" + JSON.stringify(t));\r\n}\r\n\r\nclass XLexer {\r\n   tokenize = function(sentence : IFErBase.ISentence) : any[]  {\r\n    debuglog( ()=> ' sentence prior tokenize:' + JSON.stringify(sentence));\r\n    return sentence.map( (t,index) => {\r\n         var u =  makeToken(t, index, OperatorLookup);\r\n        debuglog(\"produced nr   \" + index + \" > \" + JSON.stringify(u));\r\n        return u;\r\n    });\r\n  }\r\n};\r\n\r\nexport function getLexer()  : any {\r\n  return new XLexer();\r\n}\r\n\r\n  /* [ AFact, And,\r\n    Describe,\r\n    First, Oldest, Latest, What,\r\n    At, Every, All, At, Least, One,\r\n    The,\r\n    LParen, RParen,\r\n\r\n\r\n   Meaning, Of, Are,  In, About, You, All,\r\n  WhiteSpace, Select, From, Where, Comma, ACategory, All,\r\n    List, Identifier, Integer, GreaterThan, LessThan, To, Relating, With];\r\n*/\r\n    var SelectLexer = new Lexer(allTokens);\r\n\r\n\r\nfunction parse(tokens : any[], startrule : string) {\r\n  const parser = new SelectParser.SelectParser(tokens);\r\n  //console.log( ' ' + JSON.stringify( tokens ));\r\n  var res = parser[startrule]();\r\n   if (parser.errors.length > 0) {\r\n    debuglog(() => 'parsing error in  input:' + JSON.stringify(parser.errors,undefined,2));\r\n    var u = new Error(parser.errors[0]);\r\n    (u as any).error_obj = parser.errors[0];\r\n    throw u;\r\n  }\r\n  return res;\r\n}\r\n\r\nexport interface IParsedSentences  extends IFModel.IProcessedSentences {\r\n  asts : AST.ASTNode[],\r\n  domains? : string[]\r\n};\r\n\r\nexport declare const ERR_PARSE_ERROR = \"PARSE_ERROR\";\r\n\r\nexport function parseSentenceToAsts(s : string, model : IFModel.IModels, words : any) : IParsedSentences {\r\n  var res = ErBase.processString(s, model.rules, words, {} /*model.operators*/ );\r\n  debuglog(() =>'res > ' + JSON.stringify(res, undefined, 2));\r\n  var res2 = Object.assign({}, res as any) as IParsedSentences;\r\n  res2.errors = res2.errors || [];\r\n  res2.asts = res.sentences.map((sentence, index) => {\r\n    res2.errors[index] = false;\r\n    var lexingResult = getLexer().tokenize(sentence);\r\n    debuglog( () => {\r\n      var sStrings = lexingResult.map((t, indext) =>  `[${indext}] ${t.image} (${t.bearer && t.bearer.matchedString || JSON.stringify(sentence[index][t.startIndex])})` );\r\n      return 'tokens: #' + index + '...\\n' + sStrings.join('\\n');\r\n    });\r\n    //test.deepEqual(sStrings, ['CAT', 'CAT', 'CAT', 'CAT', 'with', 'CAT', 'FACT', 'CAT', 'FACT', 'FACT' ]);\r\n    try {\r\n      var ast = parse(lexingResult, 'catListOpMore');\r\n      debuglog(() => {\r\n        return 'ast: #' + index + '...\\n' + AST.astToText(ast);\r\n      });\r\n      return ast;\r\n    } catch (e) {\r\n      debuglog(()=> 'error  ' + JSON.stringify(e.error_obj,undefined,2) + (!e.error_obj? (e + ' ') + JSON.stringify(e): ''));\r\n      debuglog(()=> ' sentence : ' + Sentence.dumpNice(sentence));\r\n      var e2 = FormatError.formatError(e.error_obj,sentence);\r\n      res2.errors = res2.errors || [];\r\n      debuglog('parse error ' + e.toString());\r\n\r\n      res2.errors[index] = {\r\n        err_code : ERR_PARSE_ERROR,\r\n        text : e.toString().split(',\\\"token\\\":')[0]\r\n      }  as IFErBase.IERError;\r\n    }\r\n    return undefined;\r\n  });\r\n  return res2;\r\n}\r\n//\r\nexport {\r\n   SelectLexer,\r\n   parse\r\n   // defaultRule : \"selectStatement\"\r\n};\r\n"],"sourceRoot":"ABC"}